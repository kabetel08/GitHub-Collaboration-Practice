{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5026615a",
   "metadata": {},
   "source": [
    "# Computational Social Science Project #2 \n",
    "\n",
    "**Enter your Name:** Hesham Jarmakani \n",
    "\n",
    "*Semester:* Fall 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceabce6",
   "metadata": {},
   "source": [
    "Below we fill in some of the code you might use to answer some of the questions. Here are some additional resources for when you get stuck:\n",
    "* Code and documentation provided in the course notebooks  \n",
    "* [Markdown cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) to help with formatting the Jupyter notebook\n",
    "* Try Googling any errors you get and consult Stack Overflow, etc. Someone has probably had your question before!\n",
    "* Send me a pull request on GitHub flagging the syntax that's tripping you up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f76ede",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS:** For this project, copy all of the files in the Project 2 folder in the course repo into a \"Project 2\" subfolder within the \"Computational Social Science Projects\" directory that you created for the first project. You will work on the project locally, push your project to GitHub, and submit a link to the GitHub repo on bCourses by the project deadline. Be sure the final submission is in the main branch, which is what I'll pull down and re-run to grade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920223d",
   "metadata": {},
   "source": [
    "## 1. Introduction/Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013cd72b",
   "metadata": {},
   "source": [
    "#### a) Import relevant libraries\n",
    "Here are some libraries you will need to get started. Along the way you may need to add more. Best practice is to add them here at the top of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ca2b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# import libraries you might need here \n",
    "#-----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# use random seed for consistent results \n",
    "np.random.seed(273)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b23b0",
   "metadata": {},
   "source": [
    "#### b) Read in and inspect data frame \n",
    "Read in the data frame and look at some of its attributes. Read in the data contained in the projoect folder: \"Diabetes with Population Info by County 2017.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "171cd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# read in and inspect data frame\n",
    "#-----------\n",
    "# Note that \"CountyFips\" needs to be a string so the leading 0 isn't dropped (only if you want to make choropleth map) \n",
    "diabetes = pd.read_csv('Diabetes with Population Info by County 2017.csv', \n",
    "                       dtype={\"CountyFIPS\": str}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca77b1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (3220, 95)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# look at shape\n",
    "#-----------\n",
    "# look at the dimensions of the diabetes data frame\n",
    "print('shape: ', diabetes.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91328e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data types: County                                                                                                                                                   object\n",
      "State                                                                                                                                                    object\n",
      "CountyFIPS                                                                                                                                               object\n",
      "Diabetes_Number                                                                                                                                          object\n",
      "Obesity_Number                                                                                                                                           object\n",
      "Physical_Inactivity_Number                                                                                                                               object\n",
      "sex and age_total population_65 years and over_sex ratio (males per 100 females)                                                                         object\n",
      "race_total population                                                                                                                                     int64\n",
      "race_total population_one race                                                                                                                            int64\n",
      "race_total population_two or more races                                                                                                                   int64\n",
      "race_total population_one race_1                                                                                                                          int64\n",
      "race_total population_one race_white                                                                                                                      int64\n",
      "race_total population_one race_black or african american                                                                                                  int64\n",
      "race_total population_one race_american indian and alaska native                                                                                          int64\n",
      "race_total population_one race_american indian and alaska native_cherokee tribal grouping                                                                 int64\n",
      "race_total population_one race_american indian and alaska native_chippewa tribal grouping                                                                 int64\n",
      "race_total population_one race_american indian and alaska native_navajo tribal grouping                                                                   int64\n",
      "race_total population_one race_american indian and alaska native_sioux tribal grouping                                                                    int64\n",
      "race_total population_one race_asian                                                                                                                      int64\n",
      "race_total population_one race_asian_asian indian                                                                                                         int64\n",
      "race_total population_one race_asian_chinese                                                                                                              int64\n",
      "race_total population_one race_asian_filipino                                                                                                             int64\n",
      "race_total population_one race_asian_japanese                                                                                                             int64\n",
      "race_total population_one race_asian_korean                                                                                                               int64\n",
      "race_total population_one race_asian_vietnamese                                                                                                           int64\n",
      "race_total population_one race_asian_other asian                                                                                                          int64\n",
      "race_total population_one race_native hawaiian and other pacific islander                                                                                 int64\n",
      "race_total population_one race_native hawaiian and other pacific islander_native hawaiian                                                                 int64\n",
      "race_total population_one race_native hawaiian and other pacific islander_guamanian or chamorro                                                           int64\n",
      "race_total population_one race_native hawaiian and other pacific islander_samoan                                                                          int64\n",
      "race_total population_one race_native hawaiian and other pacific islander_other pacific islander                                                          int64\n",
      "race_total population_one race_some other race                                                                                                            int64\n",
      "race_total population_two or more races_1                                                                                                                 int64\n",
      "race_total population_two or more races_white and black or african american                                                                               int64\n",
      "race_total population_two or more races_white and american indian and alaska native                                                                       int64\n",
      "race_total population_two or more races_white and asian                                                                                                   int64\n",
      "race_total population_two or more races_black or african american and american indian and alaska native                                                   int64\n",
      "race alone or in combination with one or more other races_total population                                                                                int64\n",
      "race alone or in combination with one or more other races_total population_white                                                                          int64\n",
      "race alone or in combination with one or more other races_total population_black or african american                                                      int64\n",
      "race alone or in combination with one or more other races_total population_american indian and alaska native                                              int64\n",
      "race alone or in combination with one or more other races_total population_asian                                                                          int64\n",
      "race alone or in combination with one or more other races_total population_native hawaiian and other pacific islander                                     int64\n",
      "race alone or in combination with one or more other races_total population_some other race                                                                int64\n",
      "hispanic or latino and race_total population                                                                                                              int64\n",
      "hispanic or latino and race_total population_hispanic or latino (of any race)                                                                             int64\n",
      "hispanic or latino and race_total population_hispanic or latino (of any race)_mexican                                                                     int64\n",
      "hispanic or latino and race_total population_hispanic or latino (of any race)_puerto rican                                                                int64\n",
      "hispanic or latino and race_total population_hispanic or latino (of any race)_cuban                                                                       int64\n",
      "hispanic or latino and race_total population_hispanic or latino (of any race)_other hispanic or latino                                                    int64\n",
      "hispanic or latino and race_total population_not hispanic or latino                                                                                       int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_white alone                                                                           int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_black or african american alone                                                       int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_american indian and alaska native alone                                               int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_asian alone                                                                           int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_native hawaiian and other pacific islander alone                                      int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_some other race alone                                                                 int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_two or more races                                                                     int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_two or more races_two races including some other race                                 int64\n",
      "hispanic or latino and race_total population_not hispanic or latino_two or more races_two races excluding some other race -  and three or more races      int64\n",
      "total housing units                                                                                                                                       int64\n",
      "citizen -  voting age population_citizen -  18 and over population                                                                                        int64\n",
      "citizen -  voting age population_citizen -  18 and over population_male                                                                                   int64\n",
      "citizen -  voting age population_citizen -  18 and over population_female                                                                                 int64\n",
      "sex and age_total population                                                                                                                              int64\n",
      "sex and age_total population_male                                                                                                                         int64\n",
      "sex and age_total population_female                                                                                                                       int64\n",
      "sex and age_total population_sex ratio (males per 100 females)                                                                                          float64\n",
      "sex and age_total population_under 5 years                                                                                                                int64\n",
      "sex and age_total population_5 to 9 years                                                                                                                 int64\n",
      "sex and age_total population_10 to 14 years                                                                                                               int64\n",
      "sex and age_total population_15 to 19 years                                                                                                               int64\n",
      "sex and age_total population_20 to 24 years                                                                                                               int64\n",
      "sex and age_total population_25 to 34 years                                                                                                               int64\n",
      "sex and age_total population_35 to 44 years                                                                                                               int64\n",
      "sex and age_total population_45 to 54 years                                                                                                               int64\n",
      "sex and age_total population_55 to 59 years                                                                                                               int64\n",
      "sex and age_total population_60 to 64 years                                                                                                               int64\n",
      "sex and age_total population_65 to 74 years                                                                                                               int64\n",
      "sex and age_total population_75 to 84 years                                                                                                               int64\n",
      "sex and age_total population_85 years and over                                                                                                            int64\n",
      "sex and age_total population_median age (years)                                                                                                         float64\n",
      "sex and age_total population_under 18 years                                                                                                               int64\n",
      "sex and age_total population_16 years and over                                                                                                            int64\n",
      "sex and age_total population_18 years and over                                                                                                            int64\n",
      "sex and age_total population_21 years and over                                                                                                            int64\n",
      "sex and age_total population_62 years and over                                                                                                            int64\n",
      "sex and age_total population_65 years and over                                                                                                            int64\n",
      "sex and age_total population_18 years and over_1                                                                                                          int64\n",
      "sex and age_total population_18 years and over_male                                                                                                       int64\n",
      "sex and age_total population_18 years and over_female                                                                                                     int64\n",
      "sex and age_total population_18 years and over_sex ratio (males per 100 females)                                                                        float64\n",
      "sex and age_total population_65 years and over_1                                                                                                          int64\n",
      "sex and age_total population_65 years and over_male                                                                                                       int64\n",
      "sex and age_total population_65 years and over_female                                                                                                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# set pandas parameters\n",
    "#-----------\n",
    "# tells pandas how many rows to display when printing so results don't get truncated\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# look at the data types for each column in diabetes df (likely be located under each row bc column names are long)\n",
    "print('data types:', diabetes.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e77f8b",
   "metadata": {},
   "source": [
    "Immediately, we see that some of the features that should be numeric (e.g., Diabetes_Number, Obesity_Number,  and Physical_Inactivity_Number) are not. We can check to see what the non-numeric values are in a column where we are expecting numeric information with a combination of `str.isnumeric()` and `unique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72315139",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# identify non-numeric features\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#-----------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Return rows where the column \"Diabetes_Number\" is non-numeric and get the unique values of these rows\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# the \"~\" below in front of diabetes negates the str.isnumeric() so it only takes non-numeric values\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(diabetes[\u001b[38;5;241m~\u001b[39mdiabetes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiabetes_Number\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39misnumeric()][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiabetes_Number\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "#\n",
    "# identify non-numeric features\n",
    "#-----------\n",
    "# Return rows where the column \"Diabetes_Number\" is non-numeric and get the unique values of these rows\n",
    "# the \"~\" below in front of diabetes negates the str.isnumeric() so it only takes non-numeric values\n",
    "print(diabetes[~diabetes[\"Diabetes_Number\"].str.isnumeric()][\"Diabetes_Number\"].unique()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df1e47c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Data']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now do the same as above, but for \"Obesity_Number\"\n",
    "#-----------\n",
    "print(diabetes[~diabetes[\"Obesity_Number\"].str.isnumeric()][\"Obesity_Number\"].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54d1e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Data']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Now do the same as above, but for \"Physical_Inactivity_Number\" \n",
    "#-----------\n",
    "print(diabetes[~diabetes[\"Physical_Inactivity_Number\"].str.isnumeric()][\"Physical_Inactivity_Number\"].unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705636f",
   "metadata": {},
   "source": [
    "These values (\"Suppresssed\" and \"No Data\") contained in the two respective columns are coercing these features to objects instead of them being  integers. Let's drop those rows in the next section, and also recode \"Physical_Inactivity_Number\" feature to be an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a442a",
   "metadata": {},
   "source": [
    "#### c. Recode variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fe962",
   "metadata": {},
   "source": [
    "Convert 'Diabetes_Number', 'Obesity_Number', and 'Physical_Inactivity_Number' to integers below so we can use them in our analysis. Also fill in the object type we want to recode 'sex and age_total population_65 years and over_sex ratio (males per 100 females)' too (you'll have to scroll all the way over to the right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4acf34b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'No Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetes_Number\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiabetes_Number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Obesity\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# ----------\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObesity_Number\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObesity_Number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Physical Inactivity\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# ----------\u001b[39;00m\n\u001b[0;32m     21\u001b[0m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysical_Inactivity_Number\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m diabetes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysical_Inactivity_Number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CSS\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'No Data'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Recode variables\n",
    "#-----------\n",
    "\n",
    "# Diabetes\n",
    "# ----------\n",
    "# keep only useful info about our target feature, i.e., where diabetes_number not = 'Suppressed'\n",
    "# note that the inside reference to the diabetes df identifies the column, and the outer calls specific rows according to a condition \n",
    "diabetes = diabetes[diabetes['Diabetes_Number']!=\"Suppressed\"] \n",
    "\n",
    "# use the astype method on Diabetes_Number to convert it to an integer...if you are not sure, what does the astype() documentation tell you are possible arguments? \n",
    "diabetes['Diabetes_Number'] = diabetes['Diabetes_Number'].astype(int) \n",
    "\n",
    "# Obesity\n",
    "# ----------\n",
    "diabetes['Obesity_Number'] = diabetes['Obesity_Number'].astype(int) \n",
    "\n",
    "\n",
    "# Physical Inactivity\n",
    "# ----------\n",
    "diabetes['Physical_Inactivity_Number'] = diabetes['Physical_Inactivity_Number'].astype(int) \n",
    "\n",
    "\n",
    "# Some final changes \n",
    "# ----------\n",
    "# 65+ sex ratio had one \"-\" in it so let's drop that row first\n",
    "diabetes = diabetes[diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)']!= \"-\"]\n",
    "\n",
    "# change to numeric from string, since it originally included the \"-\", which made it a string\n",
    "# you'll have to decide whether to make it integer or float \n",
    "diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)'] = diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6850c",
   "metadata": {},
   "source": [
    "We should probably scale our count variables to be proportional to county population. We create the list 'rc_cols' to select all the features we want to rescale, and then use the `.div()` method to avoid typing out every single column we want to recode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Scale to county populations\n",
    "#-----------\n",
    "\n",
    "# select count variables to recode to percentages; make sure we leave out ratios and our population variable \n",
    "# because these don't make sense to scale by population\n",
    "rc_cols = [col for col in ______.columns if col not in ['County', 'State', 'CountyFIPS', \n",
    "                                                        'sex and age_total population_65 years and over_sex ratio (males per 100 females)', \n",
    "                                                        'sex and age_total population_sex ratio (males per 100 females)', \n",
    "                                                        'sex and age_total population_18 years and over_sex ratio (males per 100 females)',  \n",
    "                                                        'race_total population']]\n",
    "           \n",
    "# recode all selected columns to numeric\n",
    "diabetes[______] = diabetes[______].apply(pd.to_numeric, errors='coerce') \n",
    "\n",
    "# divide all columns but those listed above by total population to calculate rates\n",
    "diabetes[______] = diabetes[______].div(______['race_total population'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e1fe2",
   "metadata": {},
   "source": [
    "Let's check our work. Are all rates bounded by 0 and 1 as expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# check\n",
    "#-----------\n",
    "# set pandas options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# inspect recoded values\n",
    "diabetes_summary = ______.describe().transpose() # note we use the transpose method rather than .T because this object is not a numpy array\n",
    "  \n",
    "# check recoding \n",
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', None): \n",
    "    display(diabetes_summary.iloc[ : ,[0,1,3,7]]) # select which columns in the summary table we want to present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dcc070",
   "metadata": {},
   "source": [
    "#### d. Check for duplicate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce0aa",
   "metadata": {},
   "source": [
    "There are a lot of columns in this data frame. Let's see if there are any are duplicates. Note that Pandas will not allow them to have the same exact column name, so they will likely be distinct on column name but will be copies otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700163cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check for duplicate columns\n",
    "#-----------\n",
    "# I used Google to figure this out, and adapted this example for our purposes:  \n",
    "# source: https://thispointer.com/how-to-find-drop-duplicate-columns-in-a-dataframe-python-pandas/ \n",
    "def getDuplicateColumns(df):\n",
    "    '''\n",
    "    Get a list of duplicate columns.\n",
    "    It will iterate over all the columns in dataframe and find the columns whose contents are duplicate.\n",
    "    :param df: Dataframe object\n",
    "    :return: List of columns whose contents are duplicates.\n",
    "    '''\n",
    "    duplicateColumnNames = set()\n",
    "    # Iterate over all the columns in dataframe\n",
    "    for x in range(df.shape[1]):\n",
    "        # Select column at xth index.\n",
    "        col = df.iloc[:, x]\n",
    "        # Iterate over all the columns in DataFrame from (x+1)th index till end\n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "            # Select column at yth index.\n",
    "            otherCol = df.iloc[:, y]\n",
    "            # Check if two columns at x 7 y index are equal\n",
    "            if col.equals(otherCol):\n",
    "                duplicateColumnNames.add(df.columns.values[y])\n",
    "    return list(duplicateColumnNames)\n",
    "\n",
    "duplicateColumnNames = list(getDuplicateColumns(______))\n",
    "print('Duplicate Columns are as follows: ')\n",
    "duplicateColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# drop columns from duplicates list\n",
    "#-----------\n",
    "# now drop list of duplicate features from our df using the .drop() method\n",
    "diabetes = diabetes.drop(columns=______) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a85ec3",
   "metadata": {},
   "source": [
    "Finally, there are many states accounted for the in dataset. If we convert this column to a categorical variable, and create dummies, it will create a rather sparse matrix (many 0s in our dataset) becuase there will be 49 dummy variables. One alternative is to classify each state to a larger US region and use that variable instead of state. The following code will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd769e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping states to regions\n",
    "state_to_region = {\n",
    "    'Alabama': 'Southeast',\n",
    "    'Alaska': 'West',\n",
    "    'Arizona': 'West',\n",
    "    'Arkansas': 'South',\n",
    "    'California': 'West',\n",
    "    'Colorado': 'West',\n",
    "    'Connecticut': 'Northeast',\n",
    "    'Delaware': 'Northeast',\n",
    "    'District of Columbia': 'Southeast',\n",
    "    'Florida': 'Southeast',\n",
    "    'Georgia': 'Southeast',\n",
    "    'Hawaii': 'West',\n",
    "    'Idaho': 'West',\n",
    "    'Illinois': 'Midwest',\n",
    "    'Indiana': 'Midwest',\n",
    "    'Iowa': 'Midwest',\n",
    "    'Kansas': 'Midwest',\n",
    "    'Kentucky': 'South',\n",
    "    'Louisiana': 'South',\n",
    "    'Maine': 'Northeast',\n",
    "    'Maryland': 'Northeast',\n",
    "    'Massachusetts': 'Northeast',\n",
    "    'Michigan': 'Midwest',\n",
    "    'Minnesota': 'Midwest',\n",
    "    'Mississippi': 'South',\n",
    "    'Missouri': 'Midwest',\n",
    "    'Montana': 'West',\n",
    "    'Nebraska': 'Midwest',\n",
    "    'Nevada': 'West',\n",
    "    'New Hampshire': 'Northeast',\n",
    "    'New Jersey': 'Northeast',\n",
    "    'New Mexico': 'West',\n",
    "    'New York': 'Northeast',\n",
    "    'North Carolina': 'Southeast',\n",
    "    'North Dakota': 'Midwest',\n",
    "    'Ohio': 'Midwest',\n",
    "    'Oklahoma': 'South',\n",
    "    'Oregon': 'West',\n",
    "    'Pennsylvania': 'Northeast',\n",
    "    'Rhode Island': 'Northeast',\n",
    "    'South Carolina': 'Southeast',\n",
    "    'South Dakota': 'Midwest',\n",
    "    'Tennessee': 'South',\n",
    "    'Texas': 'South',\n",
    "    'Utah': 'West',\n",
    "    'Vermont': 'Northeast',\n",
    "    'Virginia': 'Southeast',\n",
    "    'Washington': 'West',\n",
    "    'West Virginia': 'South',\n",
    "    'Wisconsin': 'Midwest',\n",
    "    'Wyoming': 'West'\n",
    "}\n",
    "\n",
    "# Add a new 'Region' column based on the mapping\n",
    "diabetes['Region'] = diabetes['State'].map(state_to_region)\n",
    "\n",
    "# Print to verify'Region' column has been added\n",
    "diabetes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007b8d1",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Make at least two figures (feel free to make more) and explain their relevance to the scientific problem. The goal here is to uncover interesting patterns in the data, learn more about the scope of the problem, and communicate these findings to your audience in clear ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDA #1 and interpretations in this section \n",
    "#-----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDA #2 and interpretations in this section \n",
    "#-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df05b0",
   "metadata": {},
   "source": [
    "## 3. Prepare to Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73492869",
   "metadata": {},
   "source": [
    "### 3.1 Finalize Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67257021",
   "metadata": {},
   "source": [
    "We've already cleaned up the data, but we can make a few more adjustments before partitioning the data and training models. Let's recode 'Region' to be a categorical variable using `pd.get_dummies` and drop 'State'. Also, we'll drop 'County' because 'CountyFIPS' is already a unique identifier for the county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Drop and get dummies\n",
    "#-----------\n",
    "\n",
    "# create dummy features out of 'Region', which might be related to diabetes rates \n",
    "diabetes_clean = pd.get_dummies(______, \n",
    "                               columns = [______],  \n",
    "                               drop_first = True) # drop the first as a reference \n",
    "\n",
    "# drop 'County' and 'State' variables\n",
    "diabetes_clean = diabetes_clean.drop(labels = ['...', '...'],\n",
    "                               axis = ______) # which axis tells python we want to drop columns rather than index rows?\n",
    "\n",
    "# look at first 10 rows of new data frame \n",
    "diabetes_clean.______ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768ecd6",
   "metadata": {},
   "source": [
    "### 3.2 Partition Data, Feature Selection, and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305051f",
   "metadata": {},
   "source": [
    "Now, we will partition our data to prepare it for the training process. Ultimately we want to use a 60% train20% validation20% test in this case. More data in the training set lowers bias, but then increases variance in the validation/test sets. Balancing between bias and variance with choice of these set sizes is important as we want to ensure that there is enough data to train on to get good predictions, but also want to make sure our hold-out sets are representative enough.\n",
    "\n",
    "Work through partitioning the data into the test/train/validation sets in the chunks below. Be sure to that if you are using Ridge or LASSO, you Standardize the data. Where you do this in the workflow matters so be clear about where you are doing this and why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Partition data\n",
    "#-----------\n",
    "\n",
    "# import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create y dataframe \n",
    "y = ______\n",
    "\n",
    "# create X dataframe (include everything except \"Diabetes_Number\", our target, \n",
    "# and \"race alone or in combination with one or more other races_total population\")\n",
    "X = ______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56216906",
   "metadata": {},
   "source": [
    "Investigate whether there are any features that you should remove prior to spliting and model fitting. You may also consider using plots and relationships you found in the EDA stage for this question. Be sure to justify your logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed567cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Feature selection\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Training/test split\n",
    "#-----------\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "# split the data so that it returns 4 values: X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(...,                 # specify training dataset\n",
    "                                                    ...,                 # specify test dataset\n",
    "                                                    train_size=...,      # specify proportional split for training\n",
    "                                                    test_size=...)       # specify proportional split for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Validation split\n",
    "#-----------\n",
    "\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test, so how do we create a 60-20-20 train-validate-test split? \n",
    "X_train, X_validate, y_train, y_validate =  ______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Standardization\n",
    "#-----------\n",
    "# Given that we want to only standardize non-dichotomous variables, we need to find a \n",
    "# solution that will loop over only the columns we want to standardize. The code below\n",
    "# identifies all non-dichotomous variables in our dataset and only standardizes those.\n",
    "\n",
    "# load library and create instance of Standard Scaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# identify non-dichotomous columns we want to transform\n",
    "columns = list(X_test.select_dtypes(include=['number']).loc[:, X_test.nunique() > 2])\n",
    "\n",
    "# use loop to transform training data for only columns we want to transform\n",
    "for column in columns:\n",
    "    X_train[column] = scaler.fit_transform(X_train[column].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# use loop to transform validation data for only columns we want to transform\n",
    "for column in columns:\n",
    "    X_validate[column] = scaler.fit_transform(X_validate[column].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# use loop to transform test data for only columns we want to transform\n",
    "for column in columns:\n",
    "    X_test[column] = scaler.fit_transform(X_test[column].values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e762cb",
   "metadata": {},
   "source": [
    "## 4. Train Models\n",
    "\n",
    "In this section, train your models. \n",
    "\n",
    "**Note that if you use Lasso, you will likely need to specify a very low penalty (e.g., an alpha of 0.001) because of convergence problems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1836726",
   "metadata": {},
   "source": [
    "### 4.1 Describe models\n",
    "\n",
    "Detail the basic logic and assumptions underlying each model, its pros/cons, and why it is a plausible choice for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3818c2",
   "metadata": {},
   "source": [
    "**MODEL DESCRIPTION(S):** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b90463",
   "metadata": {},
   "source": [
    "### 4.2 Train models\n",
    "\n",
    "Train each model in the training set, and be sure to tune hyperparameters if appropriate. Report any relevant summary statistics from the training set, including how well each model fits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fb8ca",
   "metadata": {},
   "source": [
    "#### Model 1:  (enter name of model here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ddd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model 1 training\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988697f",
   "metadata": {},
   "source": [
    "#### Model 2:  (enter name of model here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model 2 training\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1f5e8",
   "metadata": {},
   "source": [
    "#### Model 3:  (enter name of model here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e375f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model 3 training\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02711ee5",
   "metadata": {},
   "source": [
    "## 5. Validate and Refine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7738d9",
   "metadata": {},
   "source": [
    "### 5.1 Predict on the validation set\n",
    "Using each of the models you trained, predict outcomes in the validation set. Evaluate how well each model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict on validation data\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efdc25",
   "metadata": {},
   "source": [
    "### 5.2 Predict on the test set\n",
    "\n",
    "Now, choose your best performing model of the three, select out unimportant feature(s), retrain the model, and then predict on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58840265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict using your best model\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79689b2a",
   "metadata": {},
   "source": [
    "### 5.3 Impement a cross-validation approach\n",
    "\n",
    "Finally, implement a cross-validation approach for your best model and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Run cross-validation\n",
    "#-----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250994bb",
   "metadata": {},
   "source": [
    "## 6. Discussion Questions\n",
    "\n",
    "In this section, insert responses for discussion questions here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fb212",
   "metadata": {},
   "source": [
    "1. What is bias-variance tradeoff? Why is it relevant to machine learning problems like this one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143ca1a",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a596d",
   "metadata": {},
   "source": [
    "2. Define overfitting, and why it matters for machine learning. How can we address it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfab1f",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64e982",
   "metadata": {},
   "source": [
    "3. Discuss your analysis in 2-3 paragraphs. Discuss your findings and recommendations. Which counties or regions would you prioritize for the pilot program? Would your answers change based on whether you want to take into account certain features such as race, gender, or age composition in the county? How confident would you be deploying this sort of model in a real-world application  why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd703e",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
